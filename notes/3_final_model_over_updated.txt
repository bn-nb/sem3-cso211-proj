\section{AN OVERVIEW OF MODEL-CENTRIC AI}

Model-Centric Approaches often follow a structured sequence during production that involves scoping the project, data collection and augmentation, data storage, data cleaning, data visualization, visual analytics, model construction and training, and finally, model evaluation. In these situations, the development and improvement of the model's algorithms typically receive the majority of the attention, with data engineering being a one-time assignment. Modern approaches also tend to analyze biases and fairness, focusing on loss functions such as Cross-Entropy, Errors in the mean square and mean absolute percentages, etc. In traditional ML production environments, a stronger emphasis is generally given to the code rather than the resultant trained model to improve its style, readability, and unambiguity. Since the models are to be trained with new data continuously, it necessitates in a broader sense for the distinctions between a data scientist and ML engineer to corrode gradually, with all collaborators developing general expertise on skills and best practices for all the domains involved. Even though model training is essential, the development of AutoML systems has resulted in the progressive decline in the requisite amount of human intervention. The model-centric design, also known as the application-centric or data-driven paradigm depending on the use case, typically necessitates minimal work on the side of the data engineer due to the conventional one-time nature of data acquisition and preprocessing. Suppose, however, data collection and model training was to become a continuous process where subsequent semi-supervised models learn from the same data they collect. In that instance, the workforce would be directed towards constantly labelling and augmentation of collected data, and a movement towards Data-Centric concepts would take place.
