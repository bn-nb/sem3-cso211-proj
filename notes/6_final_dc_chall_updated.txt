\section{CHALLENGES FACED BY DATA-CENTRIC AI TECHNOLOGIES}

Although data-centric AI appears to be a perfect replacement for model-centric perspectives, several limitations exist, which necessitates that we use both views in tandem to employ better data-engineering practices and yet continue to optimize and tune the model to fit, following conventional methodologies. Data-Centric production faces challenges such as maintaining consistency, adequate volume retention after cleaning, quality of maintenance, the necessity of a proper data versioning system, etc. Amongst the various issues, one of the most significant is the loss of volume associated with cleaning and validating data. An AI model can only receive a massive amount of high-quality data if low-quality datasets are removed.

Therefore, a data-centric method frequently needs a more significant data volume than a model-centric one. This brings potential issues where cleaning might decrease the insufficient amount of collected data under technological or monetary constraints; for example, in scientific research, the model might be continuously tuned to generate and work on experimental data. Working in a constantly evolving setting can be challenging, primarily due to the changing algorithms and margins for errors. In many cases, rules-based algorithms result in a high rejection rate because the technology needs to differentiate between authentic defective components and acceptable levels of variation, especially in manufacturing and production-based industries. This forces a large percentage of human follow-up inspection, which raises costs and slows down production lines.

Robustness is the model's ability to preserve performance with a small amount of noise in the data, such that the training error rates are consistent with testing error rates. Fairness refers to the model's tendency to defend against unnatural biases such that the model does not inadvertently introduce any biases. In the case of data quality issues, a focus is given to robust training algorithms when validation of noisy data is insufficient and/or to fairness when appropriate pre-processing levels are insufficient to remove biases from data. An AI system should be trained on the same data type it will test and analyze, including any edge-case variances. Additionally, as part of quality control methods, properties of data records that are not causative features should be randomized during training. An AI model quickly loses accuracy without consistent data annotation. Unfortunately, it can be challenging to maintain a high level of consistency. However, this brings forth a significant challenge to data-centric AI, as it requires human annotation that is costlier than machine computation, especially in environments that emphasize maximum automation.
